// ==========================================================================================
// UCR HPCC – nf-core/rnaseq – Production-Hardened Configuration
// ==========================================================================================
// Purpose: Robust, reproducible configuration for SLURM + Singularity on UCR HPCC
//
// Key Features:
//   - Native SLURM executor with smart retry logic
//   - Singularity-only (no conda/docker conflicts)
//   - Isolated caches and temp directories
//   - Node-local scratch for I/O efficiency
//   - Resource scaling via nf-core labels (not process names)
//   - Automatic retry for transient node failures
//
// Usage: Paired with 02_run_rnaseq.sh
//
// Date: October 18, 2025
// ==========================================================================================

params {
    config_profile_description = 'UCR HPCC'
    config_profile_contact     = 'Your Name Here'
    config_profile_email       = 'your.email@institution.edu'
}

// ==========================================================================================
// Container Engines
// ==========================================================================================

docker {
    enabled = false
}

conda {
    enabled = false
}

singularity {
    enabled    = true
    autoMounts = true
    cacheDir   = '/bigdata/cosmelab/lcosme/projects/albopictus-diapause-rnaseq/output/singularity'
    runOptions = '--no-home --cleanenv'
}

// ==========================================================================================
// Environment Variables
// ==========================================================================================

env {
    // Avoid tiny-stage file exception on large fan-outs
    NXF_WRAPPER_STAGE_FILE_THRESHOLD = '40000'

    // JVM heap for Nextflow runtime (prevents OOM)
    NXF_OPTS = '-Xms1g -Xmx4g'

    // Unified temp directory (project space, not $HOME or /tmp)
    TMPDIR = '/bigdata/cosmelab/lcosme/projects/albopictus-diapause-rnaseq/output/.tmp'
}

// ==========================================================================================
// SLURM Executor
// ==========================================================================================

executor {
    name            = 'slurm'
    queueSize       = 200         // Keep scheduler busy
    submitRateLimit = '15 sec'    // Gentler submission to avoid throttling on busy queues
    pollInterval    = '30 sec'    // Check job status every 30s
}

// ==========================================================================================
// Process Defaults
// ==========================================================================================

process {
    executor = 'slurm'
    queue    = 'epyc'
    shell    = ['/bin/bash', '-euo', 'pipefail']

    // Fallback defaults (nf-core labels override these)
    cpus   = 2
    memory = 8.GB
    time   = 4.h

    // Use bigdata TMPDIR instead of node-local scratch (more space, avoid quota issues)
    scratch = false

    // Retry strategy for transient failures
    // Exit codes: 143=SIGTERM, 137=SIGKILL, 104=connection reset, 134=SIGABRT
    errorStrategy = { task.exitStatus in [143, 137, 104, 134] ? 'retry' : 'terminate' }
    maxRetries    = 2
    maxErrors     = '-1'  // Don't abort whole run for intermittent node failures

    // Container isolation (removed --containall to allow TMPDIR access)
    containerOptions = ''
}

// ==========================================================================================
// Resource Scaling via nf-core Labels
// ==========================================================================================

// Heavy processes (STAR alignment, feature counting)
withLabel:process_high {
    cpus   = 16
    memory = 64.GB
    time   = 24.h
}

// Medium processes
withLabel:process_medium {
    cpus   = 8
    memory = 32.GB
    time   = 12.h
}

// Long-running processes
withLabel:process_long {
    time = 48.h
}

// High-memory processes
withLabel:process_high_memory {
    memory = 96.GB
}

// ==========================================================================================
// Optional: SLURM Account/Constraints
// ==========================================================================================

// Uncomment if your HPCC requires an account
// process.clusterOptions = '--account=cosmelab'

// Uncomment for specific node constraints
// process.clusterOptions = '--constraint=epyc'

// ==========================================================================================
// Container Overrides (Fix MultiQC Parquet Bug)
// ==========================================================================================

// MultiQC 1.29+ has a Parquet write bug that crashes with polars/thrift errors
// Override to use stable 1.28 version that doesn't use Parquet output
process {
    withName: 'NFCORE_RNASEQ:RNASEQ:MULTIQC' {
        container = 'https://depot.galaxyproject.org/singularity/multiqc:1.28--pyhdfd78af_0'
    }
}

// ==========================================================================================
// Reporting
// ==========================================================================================

// Note: Reports are enabled in launcher script via -with-report/-with-timeline/-with-trace
// Keeping them there makes it easier to customize output paths per run
